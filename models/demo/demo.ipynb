{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the Free Throw Shot Predictor\n",
    "\n",
    "This notebook runs through the entire sequence of importing, processing, and predicting on a clip named \"demo.mp4\". \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import cv2\n",
    "import skvideo.io\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from moviepy.editor import *\n",
    "from IPython.display import HTML, display\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_video(video: str, num_frames: int):\n",
    "    \"\"\"\n",
    "    Downsamples a given video clip to a given number of frames.\n",
    "    Returns an generator object to each frame in the video\n",
    "    Parameters\n",
    "    ----------\n",
    "    video:\n",
    "        - filename of video without the .mp4 extension\n",
    "    num_frames:\n",
    "        - the desired number of frames to extract\n",
    "    output_file:\n",
    "        - the filename to put the downsampled video in, with the mp4 extension omitted.\n",
    "    \"\"\"\n",
    "    clip = VideoFileClip(video)\n",
    "    duration = clip.duration\n",
    "    clip_time = 1.5\n",
    "    video_clipped = clip.subclip(0, clip_time)\n",
    "    video_downsampled = video_clipped.set_fps(num_frames/clip_time)\n",
    "    return video_downsampled.iter_frames() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(url):\n",
    "    \"\"\"\n",
    "    Load model from tensorflow hub\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url: str\n",
    "        - url of the model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The desired model\n",
    "    \"\"\"\n",
    "    module = hub.load(url)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movenet(module, input_image):\n",
    "    \"\"\"\n",
    "    Runs pose detection on an input image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    module:\n",
    "        - model loaded in from tensorflow_hub\n",
    "    input_image: tf.tensor\n",
    "        - input image of shape (1, h, w, 3) that represents input image pixels. Height and width of the image should already be resized to match the expected input resolution of the model before passing into this function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    keypoints_with_scores: np.ndarray\n",
    "        - numpy array of size (1, 1, 17, 3) representing keypoint coordinates and their confidence scores\n",
    "    \"\"\"\n",
    "    model = module.signatures['serving_default']\n",
    "\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "\n",
    "    outputs = model(input_image)\n",
    "\n",
    "    keypoints_with_scores = outputs['output_0'].numpy()\n",
    "    return keypoints_with_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Clip and run Movenet model to extract a pose vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "videogen1 = downsample_video('demo.mp4', 60)\n",
    "videogen2 = downsample_video('demo1.mp4',60)\n",
    "model = load_model(\"./saved_model\")\n",
    "input_size = 256\n",
    "row1 = np.asarray([])\n",
    "row2 = np.asarray([])\n",
    "for frame in videogen1:\n",
    "    image = frame\n",
    "    input_image = tf.expand_dims(image, axis = 0)\n",
    "    input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "    keypoints_and_scores = movenet(model, input_image)\n",
    "    keypoints = [x for i,x in enumerate(keypoints_and_scores.flatten()) if i%3!=2 or i==0]\n",
    "    row1 = np.append(row1, keypoints)\n",
    "\n",
    "for frame in videogen2:\n",
    "    image = frame\n",
    "    input_image = tf.expand_dims(image, axis = 0)\n",
    "    input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "    keypoints_and_scores = movenet(model, input_image)\n",
    "    keypoints = [x for i,x in enumerate(keypoints_and_scores.flatten()) if i%3!=2 or i==0]\n",
    "    row2 = np.append(row2, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the pose feature vector into the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 34)\n",
      "(60, 34)\n"
     ]
    }
   ],
   "source": [
    "clip1 = row1\n",
    "clip1 = np.reshape(clip1,(1,-1)) #feature vector for the clip\n",
    "numrows = int((clip1.shape[0]*clip1.shape[1])/34) #should be 60 for our standard, but this keeps it dynamic\n",
    "numcols = int((clip1.shape[0]*clip1.shape[1])/numrows) #should always end up as 34\n",
    "clip1 = np.reshape(clip1,(numrows, numcols))\n",
    "print(clip1.shape)\n",
    "\n",
    "clip2 = row2\n",
    "clip2 = np.reshape(clip2,(1,-1)) #feature vector for the clip\n",
    "numrows = int((clip2.shape[0]*clip2.shape[1])/34) #should be 60 for our standard, but this keeps it dynamic\n",
    "numcols = int((clip2.shape[0]*clip2.shape[1])/numrows) #should always end up as 34\n",
    "clip2 = np.reshape(clip2,(numrows, numcols))\n",
    "print(clip2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import our pre-trained and saved model, and run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('r2cboost.pk1','rb') as file:\n",
    "    cbm = pickle.load(file)\n",
    "\n",
    "def generatePredictions(clip):\n",
    "    #classify each row (frame) in clip\n",
    "    clipPreds = cbm.predict(clip)\n",
    "    clipSoftPreds = cbm.predict_proba(clip)[:,1]\n",
    "\n",
    "    #create singular prediction values, both hard prediction and soft score\n",
    "    prediction = np.sum(clipPreds)\n",
    "    if(prediction < (clipPreds.shape[0]/2)):\n",
    "        prediction = 0\n",
    "    else:\n",
    "        prediction = 1\n",
    "\n",
    "    softprediction = np.average(clipSoftPreds)\n",
    "    return prediction, softprediction\n",
    "\n",
    "pred1,spred1 = generatePredictions(clip1)\n",
    "pred2,spred2 = generatePredictions(clip2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION (0=Miss, 1=Make): 0\n",
      "SOFT SCORE: 0.27218008811313155\n",
      "PREDICTION (0=Miss, 1=Make): 1\n",
      "SOFT SCORE: 0.5523360731586523\n"
     ]
    }
   ],
   "source": [
    "print(\"PREDICTION (0=Miss, 1=Make): \"+str(pred1))\n",
    "print(\"SOFT SCORE: \"+str(spred1))\n",
    "print(\"PREDICTION (0=Miss, 1=Make): \"+str(pred2))\n",
    "print(\"SOFT SCORE: \"+str(spred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5eea3c5150ca7da814f918590095cf33da52d01fcbac34c29be15935182569a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
